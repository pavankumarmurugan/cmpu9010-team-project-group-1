{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the required packages\n",
    "%pip install transformers torch pandas numpy psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required packages\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "import torch\n",
    "import numpy as np\n",
    "from psycopg2.extensions import register_adapter, AsIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with empty cells (IDs):\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "file_path = '/Users/janezhang/final--project/pgvector/NLP/text-search/text-embedding-filled.csv'  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "empty_cells = df.isnull() | (df == '')\n",
    "\n",
    "\n",
    "empty_rows_ids = df.loc[empty_cells.any(axis=1), 'id']\n",
    "\n",
    "print(\"Rows with empty cells (IDs):\")\n",
    "print(empty_rows_ids.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with empty cells (IDs):\n",
      "[1468, 2645, 2646, 2743, 2744, 2745, 2746, 2747, 2748, 2749, 2750, 3878, 3879, 3880, 3881, 3882, 3883, 3884, 3885, 3886, 3887, 3888, 5248, 5249, 5250, 5251, 5252, 5253, 5254, 5255, 5256, 5257, 5258, 5259, 5260, 6630, 6631, 6632, 6633, 6634, 6635, 6636, 6637, 7128, 7129, 7130, 8100, 8101, 8102, 8103, 8104, 8105, 8291, 8292, 8293, 8958, 10133, 10134, 10280, 10313, 10314, 10315, 12079, 12080, 13020, 13021, 13022, 13023, 13180, 13249, 13303, 13304, 13517, 13518, 13519, 13520, 13521, 13522, 13687, 14115, 14116, 14117, 14118, 14119, 14120, 14121, 14338, 14339, 14342, 14361, 14362, 14363, 14364, 14365, 14437, 14692, 14693, 14694, 15396, 15397, 15631, 15632, 15633, 15634, 15635, 15636, 15637, 15638, 15639, 15803, 15804, 15805, 15806, 15807, 15808, 15809, 15810, 15811, 15812, 15813, 15814, 15815, 15816, 15817, 15840, 15841, 15842, 15843, 16027, 16044, 16045, 16169, 16170, 16692, 17434, 17435, 17501, 17502, 17503, 17504, 17505, 17544, 17545, 17546, 17547, 17999, 18000, 18127, 18128, 18129, 18164, 18223, 18224, 18236, 18237, 18238, 18239, 18240, 18241, 18242, 18243, 18244, 18245, 18246, 18289, 18290, 18755, 18756, 18757, 18872, 19216, 19565, 19816, 19928, 19929, 19932, 20115, 20378, 20450, 20451, 20756, 20757, 20758, 20973, 20974, 21152, 21153, 21189, 21190, 21333, 21494, 21495, 21496, 21990, 22020, 22260, 22386, 22387, 22432, 22503, 22504, 22505, 22506, 22507, 22508, 22509, 22510, 22511, 22512, 22513, 22617, 22675, 22676, 22677, 22683, 22684, 22685, 22686, 22728, 22830, 22831, 22894, 22923, 22937, 22969, 22984, 22985, 23216, 23257, 23258, 23409, 23410, 23483, 23881, 23882, 23883, 23962, 23963, 24038, 24039, 24413, 24601, 24710, 24711, 24712, 24713, 24714, 24742, 24743, 24744, 24745, 24831, 24832, 24833, 25210, 25627, 25706, 25718, 25719, 25736, 25771, 25815, 25816, 25999, 26174, 26630, 26631, 27374, 27375, 27439, 27440, 27441, 27442, 27443, 27444, 27445, 27470, 27705, 27706, 27762, 27936, 28064, 29073, 29074, 29075, 29076, 29671, 29713, 29714, 29758, 31641, 32610, 32617, 32618, 33016, 33017, 33018, 33019, 33020, 34053, 34225, 34453, 36058, 36059, 37384, 37385, 37412, 37420, 38556, 38557, 38990, 39015, 39258, 39367, 39368, 39369, 39483, 39484, 39485, 39486, 39571, 39573, 39956, 39957, 40015, 40016, 40109, 40110, 40111, 41657, 41658, 41871, 41872, 43899, 44443, 44444, 44763, 45005, 45006, 45007, 45008, 45009, 45010, 45011, 45012, 45292, 45790, 45882, 45892, 45902, 45903, 45904, 45905, 45906, 46011, 46761, 46762, 46763, 47027, 47104, 47159, 47160, 47351, 47352, 47366, 47706, 48913, 48914, 49042, 49534, 49535, 49536, 50458, 50459, 50460, 50461, 51409, 51410, 52301, 55354, 55355, 57545, 57859, 58272, 58273, 58274, 59023, 59024, 59025, 59026, 59027, 61443, 61444, 61445, 61579, 61580, 61581, 61582, 61583, 61584, 62433, 64803, 64804, 64805, 64881, 65009, 65010, 65832, 65833, 66508, 67761, 67839, 72721, 72722, 93145, 95625]\n",
      "Processed data saved to 'text-embedding-filled.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the CSV file\n",
    "file_path = '/Users/janezhang/final--project/pgvector/NLP/text-search/text-embedding.csv'  # 替换为你的CSV文件路径\n",
    "df = pd.read_csv(file_path, dtype={'article_id': str, 'product_code': str})\n",
    "\n",
    "# Find the positions of all empty cells\n",
    "empty_cells = df.isnull() | (df == '')\n",
    "\n",
    "# Get the 'id' column values of rows containing empty cells\n",
    "empty_rows_ids = df.loc[empty_cells.any(axis=1), 'id']\n",
    "\n",
    "# Output the IDs of rows with empty cells\n",
    "print(\"Rows with empty cells (IDs):\")\n",
    "print(empty_rows_ids.tolist())\n",
    "\n",
    "# Fill all empty cells with spaces\n",
    "df.fillna(' ', inplace=True)  \n",
    "df.replace('', ' ', inplace=True)  \n",
    "\n",
    "# Save the processed data to a new CSV file\n",
    "output_file_path = 'text-embedding-filled.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f\"Processed data saved to '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. convert numpy types into PostgreSQL-recognizable types\n",
    "def add_numpy_adapter():\n",
    "    \n",
    "    def adapt_numpy_int64(numpy_int):\n",
    "        return AsIs(numpy_int)\n",
    "    \n",
    "    def adapt_numpy_float64(numpy_float):\n",
    "        return AsIs(numpy_float)\n",
    "    \n",
    "    \n",
    "    register_adapter(np.int64, adapt_numpy_int64)\n",
    "    register_adapter(np.float64, adapt_numpy_float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the dataset and extract the required columns\n",
    "def load_and_extract_columns(file_path, columns):\n",
    "    \"\"\"\n",
    "    Read specified columns from a CSV file\n",
    "    :param file_path: The path to the CSV file\n",
    "    :param columns: A list of column names to extract\n",
    "    :return: A DataFrame containing the specified columns\n",
    "\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path, usecols=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clip_embedding(model, processor, text):\n",
    "    \n",
    "    inputs = processor(text=[text], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        embedding = model.get_text_features(**inputs).cpu().numpy().flatten()  # 生成单行向量\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_embedding_in_pgvector(conn, table_name, row, embedding):\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    INSERT INTO {table_name} (\n",
    "        article_id, product_code, product_name, product_type, product_group,\n",
    "        graphical_appearance, colour_group, perceived_colour, \n",
    "        department, index_group, section_name, detail_desc, text_vector\n",
    "    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    values = (\n",
    "        row['article_id'], row['product_code'], row['prod_name'], row['product_type_name'], row['product_group_name'],\n",
    "        row['graphical_appearance_name'], row['colour_group_name'], row['perceived_colour_value_name'], \n",
    "        row['department_name'], row['index_group_name'], row['section_name'], row['detail_desc'], embedding.tolist()\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(query, values)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/image-search/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Add numpy adapter\n",
    "    add_numpy_adapter()\n",
    "    \n",
    "    # Specify the columns to extract\n",
    "    file_path = '/Users/janezhang/final--project/pgvector/NLP/text-search/text-embedding-filled.csv'\n",
    "    columns = ['article_id', 'product_code', 'prod_name', 'product_type_name', 'product_group_name', \n",
    "               'graphical_appearance_name', 'colour_group_name', 'perceived_colour_value_name', \n",
    "               'department_name', 'index_group_name', 'section_name', 'detail_desc']  \n",
    "    \n",
    "    # Load the CLIP model\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    \n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"imageSearch\", \n",
    "        user=\"root\", \n",
    "        password=\"root\", \n",
    "        host=\"localhost\", \n",
    "        port=\"5432\"\n",
    "    )\n",
    "    \n",
    "    # Read, process, and store data row by row\n",
    "    for chunk in pd.read_csv(file_path, usecols=columns,dtype={'article_id': str, 'product_code': str}, chunksize=1):\n",
    "        row = chunk.iloc[0]  # Retrieve a single row of data\n",
    "        combined_text = ' | '.join(row.values.astype(str))  # Merge all columns of the row into a single string\n",
    "        \n",
    "        # Generate the embedding for the row's text\n",
    "        embedding = generate_clip_embedding(model, processor, combined_text)\n",
    "        \n",
    "        # Store the entire row data along with the embedding into pgvector\n",
    "        store_embedding_in_pgvector(conn, 'text_vector', row, embedding)\n",
    "    \n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
