{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain-ollama neo4j sentence-transformers llama-index\n",
    "%pip install pandas numpy\n",
    "%pip install requests\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neo4j import GraphDatabase\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "import requests\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom API: using deepbricks API\n",
    "\n",
    "# Configure Deepbricks API and model\n",
    "BASE_URL = \"\"\n",
    "API_KEY = \"\"\n",
    "MODEL_NAME = \"\"\n",
    "temperature = 0.7\n",
    "max_tokens = 150\n",
    "\n",
    "class CustomAPI:\n",
    "    def __init__(self, base_url, api_key, model):\n",
    "        self.base_url = base_url\n",
    "        self.headers = {\n",
    "            'Authorization': f'Bearer {api_key}',\n",
    "            'Content-Type': 'application/json',\n",
    "        }\n",
    "        self.model = model\n",
    "\n",
    "    def generate(self,messages, tem=temperature, max_t=max_tokens):\n",
    "        payload = {\n",
    "            'model': self.model,  # add model name\n",
    "            'messages': messages,  # send messages as context\n",
    "            'temperature': tem, # add temperature\n",
    "            'max_tokens': max_t # add max tokens\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            f'{self.base_url}',\n",
    "            headers=self.headers,\n",
    "            json=payload\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['choices'][0]['message']['content'].strip()\n",
    "        else:\n",
    "            raise Exception(f\"API call failed: {response.status_code}, {response.text}\")\n",
    "\n",
    "# using Custom API class\n",
    "llm = CustomAPI(base_url=BASE_URL, api_key=API_KEY, model=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the CSV file\n",
    "data = pd.read_csv('test-data-2.csv')\n",
    "\n",
    "# Replace NaN values with empty strings for Neo4j compatibility\n",
    "data = data.replace({np.nan: ''})\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(\"neo4j://localhost:7687\", auth=(\"neo4j\", \"test_password\"))\n",
    "\n",
    "# Creating Garment Nodes and Relationships Between Them, Creating Graph Nodes and Relationships in Neo4j\n",
    "def create_clothing_graph(tx, row):\n",
    "    query = (\n",
    "        \"\"\"\n",
    "        MERGE (c:Clothing {id: $id})\n",
    "        SET c += {name: $name, brand: $brand, type: $type, group: $group, details: $details, \n",
    "                price: $price, currency: $currency, color: $color, size: $size, \n",
    "                style: $style, pattern: $pattern, material: $material, occasion: $occasion}\n",
    "        MERGE (b:Brand {name: $brand})\n",
    "        MERGE (t:Type {name: $type})\n",
    "        MERGE (b)-[:MAKES]->(c)\n",
    "        MERGE (c)-[:BELONGS_TO]->(t)\n",
    "        \"\"\"\n",
    "    )\n",
    "    tx.run(query, id=row['id'], name=row['name'], brand=row['brand'], type=row['type'], group=row['group'], \n",
    "           details=row['details'], price=row['price'], currency=row['currency'], color=row['color'], \n",
    "           size=row['size'], style=row['style'], pattern=row['pattern'], material=row['material'], \n",
    "           occasion=row['occasion'])\n",
    "\n",
    "# Importing data into Neo4j and building graphs\n",
    "with driver.session() as session:\n",
    "    data.apply(lambda row: session.execute_write(create_clothing_graph, row), axis=1)\n",
    "\n",
    "# Deleting full-text indexes\n",
    "def delete_fulltext_index():\n",
    "    with driver.session() as session:\n",
    "        session.run(\"DROP INDEX clothingIndex IF EXISTS\")\n",
    "\n",
    "# Creating Full-Text Indexes\n",
    "def create_fulltext_index():\n",
    "    with driver.session() as session:\n",
    "        session.run(\"\"\"\n",
    "        CREATE FULLTEXT INDEX clothingIndex\n",
    "        FOR (c:Clothing)\n",
    "        ON EACH [c.id, c.name, c.brand, c.details]\n",
    "        \"\"\")\n",
    "\n",
    "# Calling the Delete Index and Create Index functions after a garment node has been created\n",
    "delete_fulltext_index()  # Delete the index first (if it exists)\n",
    "create_fulltext_index()  # Then create a new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Embedded Models\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate a description embedding vector for each garment\n",
    "data['description'] = data[['name', 'brand', 'type', 'details']].apply(lambda x: ' '.join(x), axis=1)\n",
    "embeddings = model.encode(data['description'].tolist())\n",
    "\n",
    "# Storage embedded in Neo4j\n",
    "def store_embedding(tx, name, embedding):\n",
    "    query = \"MATCH (c:Clothing {name: $name}) SET c.embedding = $embedding\"\n",
    "    tx.run(query, name=name, embedding=embedding.tolist())\n",
    "\n",
    "with driver.session() as session:\n",
    "    for i, row in data.iterrows():\n",
    "        session.write_transaction(store_embedding, row['name'], embeddings[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for full-text search\n",
    "def retrieve_products_fulltext(query):\n",
    "    with driver.session() as session:\n",
    "        # Finding matches in Clothing nodes using full-text indexing\n",
    "        result = session.run(\"\"\"\n",
    "        CALL db.index.fulltext.queryNodes('clothingIndex', $query)\n",
    "        YIELD node, score\n",
    "        RETURN node.id as id, node.name AS name, node.brand AS brand, node.details AS details, score\n",
    "        ORDER BY score DESC LIMIT 10\n",
    "        \"\"\", {\"query\": query})\n",
    "        \n",
    "        # Prints the results of each match\n",
    "        products = []\n",
    "        for record in result:\n",
    "            \n",
    "            print(f\"ID: {record['id']}, Name: {record['name']}, Brand: {record['brand']}, Details: {record['details']}, Score: {record['score']}\")\n",
    "            \n",
    "            products.append({\n",
    "                \"id\": record[\"id\"],  # Include ID\n",
    "                \"name\": record[\"name\"],\n",
    "                \"brand\": record[\"brand\"],\n",
    "                \"details\": record[\"details\"],\n",
    "                \"score\": record[\"score\"]\n",
    "            })\n",
    "\n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a prompt template\n",
    "template = \"\"\"\n",
    "User is searching for clothing. The input query is: \"{input_query}\".\n",
    "The following product data matches the query: \n",
    "{product_data}.\n",
    "Generate a response to suggest clothing.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"input_query\", \"product_data\"], template=template)\n",
    "\n",
    "# Defining the Generate Response Function\n",
    "def generate_response(openai_model, input_query, product_data):\n",
    "    combined_prompt = \"\"\"\n",
    "User is searching for clothing. The input query is: \"{}\".\n",
    "The following product data matches the query:\n",
    "{}.\n",
    "Generate a response to suggest clothing.\n",
    "\"\"\".format(input_query, product_data)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful fashion assistant\"},\n",
    "        {\"role\": \"user\", \"content\": combined_prompt}\n",
    "    ]\n",
    "\n",
    "    # Calling the OpenAI API to generate a response\n",
    "    response = openai_model.generate(messages) \n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic Keywords\n",
    "\n",
    "# TODO: extract the keywords using NLP Lib: SpaCy\n",
    "\n",
    "# TODO: Add more keywords to improve topic detection accuracy\n",
    "on_topic_keywords = ['jeans', 'dress', 'shirt', 'pants', 'clothing', 'size', 'color', 'fashion', 'outfit', 'trousers', 'jacket']\n",
    "# TODO: \n",
    "off_topic_keywords = ['weather', 'news', 'movie', 'sports', 'politics', 'celebrity', 'tv show', 'music', 'event']\n",
    "\n",
    "def detect_topic(user_input):\n",
    "    if any(word in user_input.lower() for word in on_topic_keywords):\n",
    "        return \"on_topic\"\n",
    "    elif any(word in user_input.lower() for word in off_topic_keywords):\n",
    "        return \"off_topic\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_generate_response(user_query):\n",
    "    # Retrieving Matching Clothing from Neo4j Using Full-Text Indexing\n",
    "    similar_products = retrieve_products_fulltext(user_query)  # Full-text search using user queries\n",
    "    print(\"=====================================================\")\n",
    "    print(f\"Similar products: {similar_products}\")\n",
    "\n",
    "    # Formatting product data for prompt entry\n",
    "    product_data = \", \".join([f\"{p['name']} (ID: {p['id']}, Brand: {p['brand']}, Details: {p['details']})\" for p in similar_products])\n",
    "    \n",
    "    # Print formatted product data for commissioning\n",
    "    print(\"=====================================================\")\n",
    "    print(f\"Formatted product data: {product_data}\")\n",
    "\n",
    "    # Generating Responses with Custom OpenAI Classes\n",
    "    response = generate_response(llm, user_query, product_data)\n",
    "    \n",
    "    # Returns the generated response and product data (in JSON format)\n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"products\": similar_products  # Return to full product information\n",
    "    }\n",
    "\n",
    "# Sample usage\n",
    "user_input = \"I'm looking for a white shirt with brand huili\"\n",
    "\n",
    "if detect_topic(user_input) == \"on_topic\":\n",
    "    result = search_and_generate_response(user_input)\n",
    "    print(\"=====================================================\")\n",
    "    print(result)\n",
    "elif detect_topic(user_input) == \"off_topic\":\n",
    "    print({\"response\": \"It seems your question is off-topic. Do you want to search for clothing?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
